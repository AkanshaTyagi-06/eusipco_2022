# Location-invariant-representations-for-acoustic-scene-classification
This repository consists of the python implementation for our work accepted in EUSIPCO 2022 i.e Location-invariant representations for acoustic scene classification.


# Introduction
This work is based on publicly available codes of OpenL3, Soundnet, MCCA, KMCCA and dMCCA. Their respective links are provided as a part of this repository.


### Feature Extraction

1. OpenL3 (L3-net)

      Code link : (https://github.com/marl/openl3)  
      
      Manuscript :
          Look, Listen and Learn More: Design Choices for Deep Audio Embeddings
          Jason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello.
          IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 3852â€“3856, Brighton, UK, May 2019.
  
2. Soundnet

      Code link : (https://github.com/eborboihuc/SoundNet-tensorflow)
      
      Manuscript :
          SoundNet: Learning Sound Representations from Unlabeled Video 
          Yusuf Aytar, Carl Vondrick, Antonio Torralba
          In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16)

### Multiview framework

1. MCCA (Multiset CCA)

      Code link : (https://github.com/mvlearn/mvlearn/blob/main/mvlearn/embed/mcca.py)
      
      Manuscript :
            Multi-view canonical correlation analysis
            Rupnik, Jan and Shawe-Taylor, John
            SiKDD 2010
  
2. KMCCA (Kernel MCCA)

      Code link : (https://github.com/mvlearn/mvlearn/blob/main/mvlearn/embed/kmcca.py)
      
      Manuscript :
            Multi-view canonical correlation analysis
            Rupnik, Jan and Shawe-Taylor, John
            SiKDD 2010
  
3. dMCCA (Deep MCCA)

      Code link : (https://github.com/usc-sail/mica-deep-mcca?utm_source=catalyzex.com)
      
      Manuscript :
            Multimodal Representation Learning using Deep Multiset Canonical Correlation
            Krishna Somandepalli and Naveen Kumar and Ruchir Travadi and Shrikanth Narayanan
            arXiv preprint arXiv:1904.01775, 2019
  
  
